<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Natural language inference</title>
    <meta name="description" content="">
    <meta name="generator" content="VuePress 1.3.0">
    
    
    <link rel="preload" href="/static/dataset/assets/css/0.styles.ba7cd554.css" as="style"><link rel="preload" href="/static/dataset/assets/js/app.18b431e4.js" as="script"><link rel="preload" href="/static/dataset/assets/js/2.c3866e2d.js" as="script"><link rel="preload" href="/static/dataset/assets/js/3.d90b44d3.js" as="script"><link rel="preload" href="/static/dataset/assets/js/28.d852726c.js" as="script"><link rel="prefetch" href="/static/dataset/assets/js/10.f1dac487.js"><link rel="prefetch" href="/static/dataset/assets/js/11.e3010e9b.js"><link rel="prefetch" href="/static/dataset/assets/js/12.69ab5c7e.js"><link rel="prefetch" href="/static/dataset/assets/js/13.12d77e1f.js"><link rel="prefetch" href="/static/dataset/assets/js/14.60166ccc.js"><link rel="prefetch" href="/static/dataset/assets/js/15.5a1179c8.js"><link rel="prefetch" href="/static/dataset/assets/js/16.719bd668.js"><link rel="prefetch" href="/static/dataset/assets/js/17.d8d9f4bc.js"><link rel="prefetch" href="/static/dataset/assets/js/18.ac6075e9.js"><link rel="prefetch" href="/static/dataset/assets/js/19.ae3fb24f.js"><link rel="prefetch" href="/static/dataset/assets/js/20.fa9d9a13.js"><link rel="prefetch" href="/static/dataset/assets/js/21.0ac7ccdd.js"><link rel="prefetch" href="/static/dataset/assets/js/22.23d94784.js"><link rel="prefetch" href="/static/dataset/assets/js/23.fcfcda6d.js"><link rel="prefetch" href="/static/dataset/assets/js/24.95f1b6c4.js"><link rel="prefetch" href="/static/dataset/assets/js/25.a3db53f4.js"><link rel="prefetch" href="/static/dataset/assets/js/26.5f977712.js"><link rel="prefetch" href="/static/dataset/assets/js/27.fb650c13.js"><link rel="prefetch" href="/static/dataset/assets/js/29.3aea91f5.js"><link rel="prefetch" href="/static/dataset/assets/js/30.9bfdd5d3.js"><link rel="prefetch" href="/static/dataset/assets/js/31.d88f66c4.js"><link rel="prefetch" href="/static/dataset/assets/js/32.6db44253.js"><link rel="prefetch" href="/static/dataset/assets/js/33.4923356c.js"><link rel="prefetch" href="/static/dataset/assets/js/34.a09bf3e8.js"><link rel="prefetch" href="/static/dataset/assets/js/35.ab3da096.js"><link rel="prefetch" href="/static/dataset/assets/js/36.6fb81f76.js"><link rel="prefetch" href="/static/dataset/assets/js/37.94ca99d1.js"><link rel="prefetch" href="/static/dataset/assets/js/38.d9c2f226.js"><link rel="prefetch" href="/static/dataset/assets/js/39.b4c97846.js"><link rel="prefetch" href="/static/dataset/assets/js/4.93f0fe50.js"><link rel="prefetch" href="/static/dataset/assets/js/40.9228dff7.js"><link rel="prefetch" href="/static/dataset/assets/js/41.2b8f70f5.js"><link rel="prefetch" href="/static/dataset/assets/js/42.bef5e921.js"><link rel="prefetch" href="/static/dataset/assets/js/43.ff9a4086.js"><link rel="prefetch" href="/static/dataset/assets/js/44.d0e8035a.js"><link rel="prefetch" href="/static/dataset/assets/js/45.a9d46bfa.js"><link rel="prefetch" href="/static/dataset/assets/js/46.e667b4c8.js"><link rel="prefetch" href="/static/dataset/assets/js/47.4801c9b1.js"><link rel="prefetch" href="/static/dataset/assets/js/48.80551b37.js"><link rel="prefetch" href="/static/dataset/assets/js/49.f5ed72ba.js"><link rel="prefetch" href="/static/dataset/assets/js/5.2eca2d13.js"><link rel="prefetch" href="/static/dataset/assets/js/50.1122ca28.js"><link rel="prefetch" href="/static/dataset/assets/js/51.9e4544d9.js"><link rel="prefetch" href="/static/dataset/assets/js/6.da4b743b.js"><link rel="prefetch" href="/static/dataset/assets/js/7.bb585808.js"><link rel="prefetch" href="/static/dataset/assets/js/8.866c325e.js"><link rel="prefetch" href="/static/dataset/assets/js/9.a351829b.js">
    <link rel="stylesheet" href="/static/dataset/assets/css/0.styles.ba7cd554.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="global-layout" data-v-1cbc1c23><header class="bk-dark" data-v-1cbc1c23><video autoplay="autoplay" loop="loop" muted="muted" data-v-1cbc1c23><source src="/static/dataset/assets/media/bk.417d52db.mp4" type="video/mp4" data-v-1cbc1c23></video> <div data-v-1cbc1c23><div class="header-content" data-v-1cbc1c23><h1 data-v-1cbc1c23>NLP-PROGRESS</h1> <h2 data-v-1cbc1c23>Repository to trasck the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.</h2> <a href="#" class="btn" data-v-1cbc1c23><i class="iconfont icon-github" data-v-1cbc1c23></i>
                    View on GitHub
                </a></div></div></header> <div class="theme-container no-navbar" data-v-1cbc1c23><!----> <div class="sidebar-mask"></div> <div class="sidebar-wrap sidebar-wrap-absolute"><!----></div> <main class="page"> <div class="theme-default-content content__default"><h1 id="natural-language-inference"><a href="#natural-language-inference" class="header-anchor">#</a> Natural language inference</h1> <p>Natural language inference is the task of determining whether a &quot;hypothesis&quot; is
true (entailment), false (contradiction), or undetermined (neutral) given a &quot;premise&quot;.</p> <p>Example:</p> <table><thead><tr><th>Premise</th> <th>Label</th> <th>Hypothesis</th></tr></thead> <tbody><tr><td>A man inspects the uniform of a figure in some East Asian country.</td> <td>contradiction</td> <td>The man is sleeping.</td></tr> <tr><td>An older and younger man smiling.</td> <td>neutral</td> <td>Two men are smiling and laughing at the cats playing on the floor.</td></tr> <tr><td>A soccer game with multiple males playing.</td> <td>entailment</td> <td>Some men are playing a sport.</td></tr></tbody></table> <h3 id="snli"><a href="#snli" class="header-anchor">#</a> SNLI</h3> <p>The <a href="https://arxiv.org/abs/1508.05326" target="_blank" rel="noopener noreferrer">Stanford Natural Language Inference (SNLI) Corpus<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
contains around 550k hypothesis/premise pairs. Models are evaluated based on accuracy.</p> <p>State-of-the-art results can be seen on the <a href="https://nlp.stanford.edu/projects/snli/" target="_blank" rel="noopener noreferrer">SNLI website<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <h3 id="multinli"><a href="#multinli" class="header-anchor">#</a> MultiNLI</h3> <p>The <a href="https://arxiv.org/abs/1704.05426" target="_blank" rel="noopener noreferrer">Multi-Genre Natural Language Inference (MultiNLI) corpus<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
contains around 433k hypothesis/premise pairs. It is similar to the SNLI corpus, but
covers a range of genres of spoken and written text and supports cross-genre evaluation. The data
can be downloaded from the <a href="https://www.nyu.edu/projects/bowman/multinli/" target="_blank" rel="noopener noreferrer">MultiNLI<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> website.</p> <p>Public leaderboards for <a href="https://www.kaggle.com/c/multinli-matched-open-evaluation/leaderboard" target="_blank" rel="noopener noreferrer">in-genre (matched)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
and <a href="https://www.kaggle.com/c/multinli-mismatched-open-evaluation/leaderboard" target="_blank" rel="noopener noreferrer">cross-genre (mismatched)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
evaluation are available, but entries do not correspond to published models.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">Matched</th> <th style="text-align:center;">Mismatched</th> <th>Paper / Source</th> <th>Code</th></tr></thead> <tbody><tr><td>RoBERTa (Liu et al., 2019)</td> <td style="text-align:center;">90.8</td> <td style="text-align:center;">90.2</td> <td><a href="https://arxiv.org/pdf/1907.11692.pdf" target="_blank" rel="noopener noreferrer">RoBERTa: A Robustly Optimized BERT Pretraining Approach<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/pytorch/fairseq/blob/master/examples/roberta/README.md" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>XLNet-Large (ensemble) (Yang et al., 2019)</td> <td style="text-align:center;">90.2</td> <td style="text-align:center;">89.8</td> <td><a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener noreferrer">XLNet: Generalized Autoregressive Pretraining for Language Understanding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/zihangdai/xlnet/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MT-DNN-ensemble (Liu et al., 2019)</td> <td style="text-align:center;">87.9</td> <td style="text-align:center;">87.4</td> <td><a href="https://arxiv.org/pdf/1904.09482.pdf" target="_blank" rel="noopener noreferrer">Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/namisan/mt-dnn/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Snorkel MeTaL(ensemble) (Ratner et al., 2018)</td> <td style="text-align:center;">87.6</td> <td style="text-align:center;">87.2</td> <td><a href="https://arxiv.org/pdf/1810.02840.pdf" target="_blank" rel="noopener noreferrer">Training Complex Models with Multi-Task Weak Supervision<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/HazyResearch/metal" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Finetuned Transformer LM (Radford et al., 2018)</td> <td style="text-align:center;">82.1</td> <td style="text-align:center;">81.4</td> <td><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener noreferrer">Improving Language Understanding by Generative Pre-Training<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr> <tr><td>Multi-task BiLSTM + Attn (Wang et al., 2018)</td> <td style="text-align:center;">72.2</td> <td style="text-align:center;">72.1</td> <td><a href="https://arxiv.org/abs/1804.07461" target="_blank" rel="noopener noreferrer">GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr> <tr><td>GenSen (Subramanian et al., 2018)</td> <td style="text-align:center;">71.4</td> <td style="text-align:center;">71.3</td> <td><a href="https://arxiv.org/abs/1804.00079" target="_blank" rel="noopener noreferrer">Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr></tbody></table> <h3 id="scitail"><a href="#scitail" class="header-anchor">#</a> SciTail</h3> <p>The <a href="http://ai2-website.s3.amazonaws.com/publications/scitail-aaai-2018_cameraready.pdf" target="_blank" rel="noopener noreferrer">SciTail<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
entailment dataset consists of 27k. In contrast to the SNLI and MultiNLI, it was not crowd-sourced
but created from sentences that already exist &quot;in the wild&quot;. Hypotheses were created from
science questions and the corresponding answer candidates, while relevant web sentences from a large
corpus were used as premises. Models are evaluated based on accuracy.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">Accuracy</th> <th>Paper / Source</th></tr></thead> <tbody><tr><td>Finetuned Transformer LM (Radford et al., 2018)</td> <td style="text-align:center;">88.3</td> <td><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener noreferrer">Improving Language Understanding by Generative Pre-Training<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Hierarchical BiLSTM Max Pooling (Talman et al., 2018)</td> <td style="text-align:center;">86.0</td> <td><a href="https://arxiv.org/abs/1808.08762" target="_blank" rel="noopener noreferrer">Natural Language Inference with Hierarchical BiLSTM Max Pooling<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>CAFE (Tay et al., 2018)</td> <td style="text-align:center;">83.3</td> <td><a href="https://arxiv.org/abs/1801.00102" target="_blank" rel="noopener noreferrer">A Compare-Propagate Architecture with Alignment Factorization for Natural Language Inference<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr></tbody></table> <p><a href="/static/dataset/" class="router-link-active">Go back to the README</a></p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div> <footer class="bk-dark" data-v-1cbc1c23><div class="footer-content" data-v-1cbc1c23><p data-v-1cbc1c23>NLP-progress maintained by <a href="https://github.com/sebastianruder" data-v-1cbc1c23>sebastianruder</a></p> <p data-v-1cbc1c23>Published with <a href="https://github.com/sebastianruder" data-v-1cbc1c23>GitHub Pages</a></p></div></footer></div><div class="global-ui"></div></div>
    <script src="/static/dataset/assets/js/app.18b431e4.js" defer></script><script src="/static/dataset/assets/js/2.c3866e2d.js" defer></script><script src="/static/dataset/assets/js/3.d90b44d3.js" defer></script><script src="/static/dataset/assets/js/28.d852726c.js" defer></script>
  </body>
</html>

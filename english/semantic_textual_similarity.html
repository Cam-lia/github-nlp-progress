<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Semantic textual similarity</title>
    <meta name="description" content="">
    <meta name="generator" content="VuePress 1.3.0">
    
    
    <link rel="preload" href="/static/dataset/assets/css/0.styles.ba7cd554.css" as="style"><link rel="preload" href="/static/dataset/assets/js/app.18b431e4.js" as="script"><link rel="preload" href="/static/dataset/assets/js/2.c3866e2d.js" as="script"><link rel="preload" href="/static/dataset/assets/js/3.d90b44d3.js" as="script"><link rel="preload" href="/static/dataset/assets/js/35.ab3da096.js" as="script"><link rel="prefetch" href="/static/dataset/assets/js/10.f1dac487.js"><link rel="prefetch" href="/static/dataset/assets/js/11.e3010e9b.js"><link rel="prefetch" href="/static/dataset/assets/js/12.69ab5c7e.js"><link rel="prefetch" href="/static/dataset/assets/js/13.12d77e1f.js"><link rel="prefetch" href="/static/dataset/assets/js/14.60166ccc.js"><link rel="prefetch" href="/static/dataset/assets/js/15.5a1179c8.js"><link rel="prefetch" href="/static/dataset/assets/js/16.719bd668.js"><link rel="prefetch" href="/static/dataset/assets/js/17.d8d9f4bc.js"><link rel="prefetch" href="/static/dataset/assets/js/18.ac6075e9.js"><link rel="prefetch" href="/static/dataset/assets/js/19.ae3fb24f.js"><link rel="prefetch" href="/static/dataset/assets/js/20.fa9d9a13.js"><link rel="prefetch" href="/static/dataset/assets/js/21.0ac7ccdd.js"><link rel="prefetch" href="/static/dataset/assets/js/22.23d94784.js"><link rel="prefetch" href="/static/dataset/assets/js/23.fcfcda6d.js"><link rel="prefetch" href="/static/dataset/assets/js/24.95f1b6c4.js"><link rel="prefetch" href="/static/dataset/assets/js/25.a3db53f4.js"><link rel="prefetch" href="/static/dataset/assets/js/26.5f977712.js"><link rel="prefetch" href="/static/dataset/assets/js/27.fb650c13.js"><link rel="prefetch" href="/static/dataset/assets/js/28.d852726c.js"><link rel="prefetch" href="/static/dataset/assets/js/29.3aea91f5.js"><link rel="prefetch" href="/static/dataset/assets/js/30.9bfdd5d3.js"><link rel="prefetch" href="/static/dataset/assets/js/31.d88f66c4.js"><link rel="prefetch" href="/static/dataset/assets/js/32.6db44253.js"><link rel="prefetch" href="/static/dataset/assets/js/33.4923356c.js"><link rel="prefetch" href="/static/dataset/assets/js/34.a09bf3e8.js"><link rel="prefetch" href="/static/dataset/assets/js/36.6fb81f76.js"><link rel="prefetch" href="/static/dataset/assets/js/37.94ca99d1.js"><link rel="prefetch" href="/static/dataset/assets/js/38.d9c2f226.js"><link rel="prefetch" href="/static/dataset/assets/js/39.b4c97846.js"><link rel="prefetch" href="/static/dataset/assets/js/4.93f0fe50.js"><link rel="prefetch" href="/static/dataset/assets/js/40.9228dff7.js"><link rel="prefetch" href="/static/dataset/assets/js/41.2b8f70f5.js"><link rel="prefetch" href="/static/dataset/assets/js/42.bef5e921.js"><link rel="prefetch" href="/static/dataset/assets/js/43.ff9a4086.js"><link rel="prefetch" href="/static/dataset/assets/js/44.d0e8035a.js"><link rel="prefetch" href="/static/dataset/assets/js/45.a9d46bfa.js"><link rel="prefetch" href="/static/dataset/assets/js/46.e667b4c8.js"><link rel="prefetch" href="/static/dataset/assets/js/47.4801c9b1.js"><link rel="prefetch" href="/static/dataset/assets/js/48.80551b37.js"><link rel="prefetch" href="/static/dataset/assets/js/49.f5ed72ba.js"><link rel="prefetch" href="/static/dataset/assets/js/5.2eca2d13.js"><link rel="prefetch" href="/static/dataset/assets/js/50.1122ca28.js"><link rel="prefetch" href="/static/dataset/assets/js/51.9e4544d9.js"><link rel="prefetch" href="/static/dataset/assets/js/6.da4b743b.js"><link rel="prefetch" href="/static/dataset/assets/js/7.bb585808.js"><link rel="prefetch" href="/static/dataset/assets/js/8.866c325e.js"><link rel="prefetch" href="/static/dataset/assets/js/9.a351829b.js">
    <link rel="stylesheet" href="/static/dataset/assets/css/0.styles.ba7cd554.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="global-layout" data-v-1cbc1c23><header class="bk-dark" data-v-1cbc1c23><video autoplay="autoplay" loop="loop" muted="muted" data-v-1cbc1c23><source src="/static/dataset/assets/media/bk.417d52db.mp4" type="video/mp4" data-v-1cbc1c23></video> <div data-v-1cbc1c23><div class="header-content" data-v-1cbc1c23><h1 data-v-1cbc1c23>NLP-PROGRESS</h1> <h2 data-v-1cbc1c23>Repository to trasck the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.</h2> <a href="#" class="btn" data-v-1cbc1c23><i class="iconfont icon-github" data-v-1cbc1c23></i>
                    View on GitHub
                </a></div></div></header> <div class="theme-container no-navbar" data-v-1cbc1c23><!----> <div class="sidebar-mask"></div> <div class="sidebar-wrap sidebar-wrap-absolute"><aside class="sidebar"><!---->  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>目录</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/static/dataset/english/semantic_textual_similarity.html#paraphrase-identification" class="sidebar-link">Paraphrase identification</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/static/dataset/english/semantic_textual_similarity.html#quora-question-pairs" class="sidebar-link">Quora Question Pairs</a></li></ul></li></ul></section></li></ul> </aside></div> <main class="page"> <div class="theme-default-content content__default"><h1 id="semantic-textual-similarity"><a href="#semantic-textual-similarity" class="header-anchor">#</a> Semantic textual similarity</h1> <p>Semantic textual similarity deals with determining how similar two pieces of texts are.
This can take the form of assigning a score from 1 to 5. Related tasks are paraphrase or duplicate identification.</p> <h3 id="senteval"><a href="#senteval" class="header-anchor">#</a> SentEval</h3> <p><a href="https://arxiv.org/abs/1803.05449" target="_blank" rel="noopener noreferrer">SentEval<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> is an evaluation toolkit for evaluating sentence
representations. It includes 17 downstream tasks, including common semantic textual similarity
tasks. The semantic textual similarity (STS) benchmark tasks from 2012-2016 (STS12, STS13, STS14, STS15, STS16, STS-B) measure the relatedness
of two sentences based on the cosine similarity of the two representations. The evaluation criterion is Pearson correlation.</p> <p>The SICK relatedness (SICK-R) task trains a linear model to output a score from 1 to 5 indicating the relatedness of two sentences. For
the same dataset (SICK-E) can be treated as a three-class classification problem using the entailment labels (classes are 'entailment', 'contradiction', and 'neutral').
The evaluation metric for SICK-R is Pearson correlation and classification accuracy for SICK-E.</p> <p>The Microsoft Research Paraphrase Corpus (MRPC) corpus is a paraphrase identification dataset, where systems
aim to identify if two sentences are paraphrases of each other. The evaluation metric is classification accuracy and F1.</p> <p>The data can be downloaded from <a href="https://github.com/facebookresearch/SentEval" target="_blank" rel="noopener noreferrer">here<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">MRPC</th> <th style="text-align:center;">SICK-R</th> <th style="text-align:center;">SICK-E</th> <th style="text-align:center;">STS</th> <th>Paper / Source</th> <th>Code</th></tr></thead> <tbody><tr><td>XLNet-Large (ensemble) (Yang et al., 2019)</td> <td style="text-align:center;">93.0/90.7</td> <td style="text-align:center;">-</td> <td style="text-align:center;">-</td> <td style="text-align:center;">91.6/91.1*</td> <td><a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener noreferrer">XLNet: Generalized Autoregressive Pretraining for Language Understanding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/zihangdai/xlnet/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MT-DNN-ensemble (Liu et al., 2019)</td> <td style="text-align:center;">92.7/90.3</td> <td style="text-align:center;">-</td> <td style="text-align:center;">-</td> <td style="text-align:center;">91.1/90.7*</td> <td><a href="https://arxiv.org/pdf/1904.09482.pdf" target="_blank" rel="noopener noreferrer">Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/namisan/mt-dnn/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Snorkel MeTaL(ensemble) (Ratner et al., 2018)</td> <td style="text-align:center;">91.5/88.5</td> <td style="text-align:center;">-</td> <td style="text-align:center;">-</td> <td style="text-align:center;">90.1/89.7*</td> <td><a href="https://arxiv.org/pdf/1810.02840.pdf" target="_blank" rel="noopener noreferrer">Training Complex Models with Multi-Task Weak Supervision<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/HazyResearch/metal" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>GenSen (Subramanian et al., 2018)</td> <td style="text-align:center;">78.6/84.4</td> <td style="text-align:center;">0.888</td> <td style="text-align:center;">87.8</td> <td style="text-align:center;">78.9/78.6</td> <td><a href="https://arxiv.org/abs/1804.00079" target="_blank" rel="noopener noreferrer">Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/Maluuba/gensen" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>InferSent (Conneau et al., 2017)</td> <td style="text-align:center;">76.2/83.1</td> <td style="text-align:center;">0.884</td> <td style="text-align:center;">86.3</td> <td style="text-align:center;">75.8/75.5</td> <td><a href="https://arxiv.org/abs/1705.02364" target="_blank" rel="noopener noreferrer">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/facebookresearch/InferSent" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>TF-KLD (Ji and Eisenstein, 2013)</td> <td style="text-align:center;">80.4/85.9</td> <td style="text-align:center;">-</td> <td style="text-align:center;">-</td> <td style="text-align:center;">-</td> <td><a href="http://www.aclweb.org/anthology/D/D13/D13-1090.pdf" target="_blank" rel="noopener noreferrer">Discriminative Improvements to Distributional Sentence Similarity<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr></tbody></table> <p>* only evaluated on STS-B</p> <h2 id="paraphrase-identification"><a href="#paraphrase-identification" class="header-anchor">#</a> Paraphrase identification</h2> <h3 id="quora-question-pairs"><a href="#quora-question-pairs" class="header-anchor">#</a> Quora Question Pairs</h3> <p>The <a href="https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs" target="_blank" rel="noopener noreferrer">Quora Question Pairs dataset<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
consists of over 400,000 pairs of questions on Quora. Systems must identify whether one question is a
duplicate of the other. Models are evaluated based on accuracy.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">F1</th> <th style="text-align:center;">Accuracy</th> <th>Paper / Source</th> <th>Code</th></tr></thead> <tbody><tr><td>XLNet-Large (ensemble) (Yang et al., 2019)</td> <td style="text-align:center;">74.2</td> <td style="text-align:center;">90.3</td> <td><a href="https://arxiv.org/pdf/1906.08237.pdf" target="_blank" rel="noopener noreferrer">XLNet: Generalized Autoregressive Pretraining for Language Understanding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/zihangdai/xlnet/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MT-DNN-ensemble (Liu et al., 2019)</td> <td style="text-align:center;">73.7</td> <td style="text-align:center;">89.9</td> <td><a href="https://arxiv.org/pdf/1904.09482.pdf" target="_blank" rel="noopener noreferrer">Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/namisan/mt-dnn/" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Snorkel MeTaL(ensemble) (Ratner et al., 2018)</td> <td style="text-align:center;">73.1</td> <td style="text-align:center;">89.9</td> <td><a href="https://arxiv.org/pdf/1810.02840.pdf" target="_blank" rel="noopener noreferrer">Training Complex Models with Multi-Task Weak Supervision<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/HazyResearch/metal" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MwAN (Tan et al., 2018)</td> <td style="text-align:center;"></td> <td style="text-align:center;">89.12</td> <td><a href="https://www.ijcai.org/proceedings/2018/0613.pdf" target="_blank" rel="noopener noreferrer">Multiway Attention Networks for Modeling Sentence Pairs<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr> <tr><td>DIIN (Gong et al., 2018)</td> <td style="text-align:center;"></td> <td style="text-align:center;">89.06</td> <td><a href="https://arxiv.org/pdf/1709.04348.pdf" target="_blank" rel="noopener noreferrer">Natural Language Inference Over Interaction Space<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/YichenGong/Densely-Interactive-Inference-Network" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>pt-DecAtt (Char) (Tomar et al., 2017)</td> <td style="text-align:center;"></td> <td style="text-align:center;">88.40</td> <td><a href="https://arxiv.org/abs/1704.04565" target="_blank" rel="noopener noreferrer">Neural Paraphrase Identification of Questions with Noisy Pretraining<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td></td></tr> <tr><td>BiMPM (Wang et al., 2017)</td> <td style="text-align:center;"></td> <td style="text-align:center;">88.17</td> <td><a href="https://arxiv.org/abs/1702.03814" target="_blank" rel="noopener noreferrer">Bilateral Multi-Perspective Matching for Natural Language Sentences<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/zhiguowang/BiMPM" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>GenSen (Subramanian et al., 2018)</td> <td style="text-align:center;"></td> <td style="text-align:center;">87.01</td> <td><a href="https://arxiv.org/abs/1804.00079" target="_blank" rel="noopener noreferrer">Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td> <td><a href="https://github.com/Maluuba/gensen" target="_blank" rel="noopener noreferrer">Official<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr></tbody></table> <p><a href="/static/dataset/" class="router-link-active">Go back to the README</a></p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div> <footer class="bk-dark" data-v-1cbc1c23><div class="footer-content" data-v-1cbc1c23><p data-v-1cbc1c23>NLP-progress maintained by <a href="https://github.com/sebastianruder" data-v-1cbc1c23>sebastianruder</a></p> <p data-v-1cbc1c23>Published with <a href="https://github.com/sebastianruder" data-v-1cbc1c23>GitHub Pages</a></p></div></footer></div><div class="global-ui"></div></div>
    <script src="/static/dataset/assets/js/app.18b431e4.js" defer></script><script src="/static/dataset/assets/js/2.c3866e2d.js" defer></script><script src="/static/dataset/assets/js/3.d90b44d3.js" defer></script><script src="/static/dataset/assets/js/35.ab3da096.js" defer></script>
  </body>
</html>

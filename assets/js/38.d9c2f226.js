(window.webpackJsonp=window.webpackJsonp||[]).push([[38],{259:function(t,e,n){"use strict";n.r(e);var a=n(1),r=Object(a.a)({},(function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"simplification"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#simplification"}},[t._v("#")]),t._v(" Simplification")]),t._v(" "),n("p",[t._v("Simplification consists of modifying the content and structure of a text in order to make it easier to read and understand, while preserving its main idea and approximating its original meaning. A simplified version of a text could benefit low literacy readers, English learners, children, and people with aphasia, dyslexia or autism. Also, simplifying a text automatically could improve performance on other NLP tasks, such as parsing, summarisation, information extraction, semantic role labeling, and machine translation.")]),t._v(" "),n("h2",{attrs:{id:"sentence-simplification"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sentence-simplification"}},[t._v("#")]),t._v(" Sentence Simplification")]),t._v(" "),n("p",[t._v("Research on automatic simplification has been traditionally limited to executing transformations at the sentence-level. What should we expect from a sentence simplificatin model? Let's take a look at how humans simplify (from "),n("a",{attrs:{href:"http://videolectures.net/esslli2011_lapata_simplification/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),n("OutboundLink")],1),t._v("):")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("Original Sentence")]),t._v(" "),n("th",[t._v("Simplified   Sentence")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("Owls are the order Strigiformes, comprising 200 bird of prey species.")]),t._v(" "),n("td",[t._v("An owl is a bird. There are about 200 kinds of owls.")])]),t._v(" "),n("tr",[n("td",[t._v("Owls hunt mostly small mammals, insects, and other birds though some species specialize in hunting fish.")]),t._v(" "),n("td",[t._v("Owls’ prey may be birds, large insects (such as crickets), small reptiles (such as lizards) or small mammals (such as mice, rats, and rabbits).")])])])]),t._v(" "),n("p",[t._v("Notice the simplification transformations performed:")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("Unusual concepts are explained: insects "),n("em",[t._v("(such as crickets)")]),t._v(", small reptiles "),n("em",[t._v("(such as lizards)")]),t._v(" or small mammals "),n("em",[t._v("(such as mice, rats, and rabbits)")]),t._v(".")])]),t._v(" "),n("li",[n("p",[t._v('Uncommon words are replaced with a more familiar term or phrase: "comprising" → "There are about".')])]),t._v(" "),n("li",[n("p",[t._v("Syntactic structures are changed by a simpler pattern. For example, the first sentence is split into two.")])]),t._v(" "),n("li",[n("p",[t._v("Some "),n("em",[t._v("unimportant")]),t._v(' information is removed: the clause "though some species specialize in hunting fish" in the second sentence does not appear in its simplified version.')])])]),t._v(" "),n("p",[t._v("When the set of transformations is limited to replacing a word or phrase by a simpler synonym, we are dealing with "),n("em",[t._v("Lexical Simplification")]),t._v(" (an overview of that area can be found "),n("a",{attrs:{href:"https://www.jair.org/index.php/jair/article/view/11091/26278",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),n("OutboundLink")],1),t._v("). In this section, we consider research that attempts to develop models that learn as many text transformations as possible.")]),t._v(" "),n("h3",{attrs:{id:"evaluation"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#evaluation"}},[t._v("#")]),t._v(" Evaluation")]),t._v(" "),n("p",[t._v("The ideal method for determining the quality of a simplification is through human evaluation. Traditionally, a simplified output is judged in terms of "),n("em",[t._v("grammaticality")]),t._v(" (or fluency), "),n("em",[t._v("meaning preservation")]),t._v(" (or adequacy) and "),n("em",[t._v("simplicity")]),t._v(", using Likert scales (1-3 or 1-5) . "),n("strong",[t._v("Warning:")]),t._v(" Are these criteria (at the sentence level) the most appropriate for assessing a simplified sentence? It has been suggested "),n("a",{attrs:{href:"https://www.jbe-platform.com/content/journals/10.1075/itl.165.2.06sid",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Siddharthan, 2014)"),n("OutboundLink")],1),t._v(" that a task-oriented evaluation (e.g. through reading comprehension tests "),n("a",{attrs:{href:"http://aclweb.org/anthology/C14-1188",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Angrosh et al., 2014)"),n("OutboundLink")],1),t._v(") could be more informative of the usefulness of the generated simplification. However, this is not general practice.")]),t._v(" "),n("p",[t._v("For tuning and comparing models, the most commonly-used automatic metrics are:")]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("BLEU")]),t._v(" "),n("a",{attrs:{href:"https://aclweb.org/anthology/P02-1040",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Papineni et al., 2012)"),n("OutboundLink")],1),t._v(", borrowed from Machine Translation. This metric is not one without "),n("a",{attrs:{href:"https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213",target:"_blank",rel:"noopener noreferrer"}},[t._v("problems"),n("OutboundLink")],1),t._v(" for different text generation tasks. However, simplification studies ("),n("a",{attrs:{href:"http://aclweb.org/anthology/W14-1201",target:"_blank",rel:"noopener noreferrer"}},[t._v("Stajner et al., 2014"),n("OutboundLink")],1),t._v("; "),n("a",{attrs:{href:"http://aclweb.org/anthology/P12-1107",target:"_blank",rel:"noopener noreferrer"}},[t._v("Wubben et al., 2012"),n("OutboundLink")],1),t._v("; "),n("a",{attrs:{href:"http://aclweb.org/anthology/Q16-1029",target:"_blank",rel:"noopener noreferrer"}},[t._v("Xu et al., 2016"),n("OutboundLink")],1),t._v(") have shown that it correlates with human judgments of grammaticality and meaning preservation. BLEU is not well suited, though, for assessing simplicity from a lexical "),n("a",{attrs:{href:"http://aclweb.org/anthology/Q16-1029",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Xu et al., 2016)"),n("OutboundLink")],1),t._v(" nor a structural "),n("a",{attrs:{href:"http://aclweb.org/anthology/D18-1081",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Sulem et al., 2018b)"),n("OutboundLink")],1),t._v(" point of view.")]),t._v(" "),n("li",[n("strong",[t._v("SARI")]),t._v(" "),n("a",{attrs:{href:"http://aclweb.org/anthology/Q16-1029",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Xu et al., 2016)"),n("OutboundLink")],1),t._v(" is a "),n("em",[t._v("lexical simplicity")]),t._v(' metric that measures "how good" are the words added, deleted and kept by a simplification model. The metric compares the model\'s output to '),n("em",[t._v("multiple simplification references")]),t._v(" and the original sentence. SARI has shown high correlation with human judgements of simplicity gain "),n("a",{attrs:{href:"http://aclweb.org/anthology/Q16-1029",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Xu et al., 2016)"),n("OutboundLink")],1),t._v(". Currently, this is the main metric used for evaluating sentence simplification models.")])]),t._v(" "),n("p",[t._v("The previous two metrics will be used to rank the models in the following sections. Despite popular practice, we refrain from using "),n("strong",[t._v("Flesch Reading Ease")]),t._v(" or "),n("strong",[t._v("Flesch-Kincaid Grade Level")]),t._v(". Because of the way these metrics are "),n("a",{attrs:{href:"https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests",target:"_blank",rel:"noopener noreferrer"}},[t._v("computed"),n("OutboundLink")],1),t._v(", short sentences could get good scores, even if they are ungrammatical or non-meaning preserving "),n("a",{attrs:{href:"http://aclweb.org/anthology/P12-1107",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Wubben et al., 2012)"),n("OutboundLink")],1),t._v(", resulting in a missleading ranking.")]),t._v(" "),n("p",[t._v("Since a simplification could involve text transformations beyond paraphrasing (which SARI intends to assess).  For these cases, it could be more suitable to use "),n("strong",[t._v("SAMSA")]),t._v(" "),n("a",{attrs:{href:"http://aclweb.org/anthology/N18-1063",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Sulem et al., 2018a)"),n("OutboundLink")],1),t._v(", a metric designed to measure "),n("em",[t._v("structural simplicity")]),t._v(" (i.e. sentence splitting). However, it has not been used in papers besides the one where it was introduced (yet).")]),t._v(" "),n("p",[n("strong",[t._v("EASSE:")]),t._v(" "),n("a",{attrs:{href:"https://www.aclweb.org/anthology/D19-3009",target:"_blank",rel:"noopener noreferrer"}},[t._v("Alva-Manchego et al. (2019)"),n("OutboundLink")],1),t._v(" released a "),n("a",{attrs:{href:"https://github.com/feralvam/easse",target:"_blank",rel:"noopener noreferrer"}},[t._v("tool"),n("OutboundLink")],1),t._v(" that provides easy access to all of the above metrics (and several others) through the command line and as a python package. EASSE also contains commonly-used test sets for the task. Its aim is to help standarise automatic evaluation for sentence simplification.")]),t._v(" "),n("p",[n("strong",[t._v("IMPORTANT NOTE:")]),t._v(" In the tables of the following sections, a score with a * means that it was not reported by the original authors but by future research that re-implemented and/or re-trained and re-tested the model. In these cases, the original reported score (if there is one) is shown in parentheses.")]),t._v(" "),n("h3",{attrs:{id:"main-simple-english-wikipedia"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#main-simple-english-wikipedia"}},[t._v("#")]),t._v(" Main - Simple English Wikipedia")]),t._v(" "),n("p",[n("a",{attrs:{href:"https://simple.wikipedia.org",target:"_blank",rel:"noopener noreferrer"}},[t._v("Simple English Wikipedia"),n("OutboundLink")],1),t._v(" is an online encyclopedia aimed at English learners. Its articles are expected to contain fewer words and simpler grammar structures than those in their "),n("a",{attrs:{href:"https://en.wikipedia.org",target:"_blank",rel:"noopener noreferrer"}},[t._v("Main English Wikipedia"),n("OutboundLink")],1),t._v(" counterpart. Much of the popularity of using Wikipedia for research in Simplification comes from publicly available sentence alignments between “equivalent” articles in Main and Simple English Wikipedia.")]),t._v(" "),n("h4",{attrs:{id:"pwkp-wikismall"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#pwkp-wikismall"}},[t._v("#")]),t._v(" PWKP / WikiSmall")]),t._v(" "),n("p",[n("a",{attrs:{href:"http://aclweb.org/anthology/C10-1152",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zu et al. (2010)"),n("OutboundLink")],1),t._v(" compiled a parallel corpus with more than 108K sentence pairs from 65,133 Wikipedia articles, allowing "),n("strong",[t._v("1-to-1 and 1-to-N alignments")]),t._v(". The latter type of alignments represents instances of sentence splitting. The original full corpus can be found "),n("a",{attrs:{href:"https://www.informatik.tu-darmstadt.de/ukp/research_6/data/sentence_simplification/simple_complex_sentence_pairs/index.en.jsp",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),n("OutboundLink")],1),t._v(". The test set is composed of 100 instances, with "),n("strong",[t._v("one simplification reference per original sentence")]),t._v(". "),n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zhang and Lapata (2017)"),n("OutboundLink")],1),t._v(" released a more standardised split of this dataset called "),n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[n("em",[t._v("WikiSmall")]),n("OutboundLink")],1),t._v(", with 89,042 instances for training, 205 for development and the same original 100 instances for testing.")]),t._v(" "),n("p",[t._v("We present the models tested in this dataset "),n("strong",[t._v("ranked by BLEU score")]),t._v(" (or SARI if BLEU is not available). SARI cannot be reliably computed in this dataset since it does not contain multiple simplification references per original sentence. In addition, there are instances of more advanced simplification transformations (e.g. splitting) which SARI does not assess by definition.")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("Model")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("BLEU")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("SARI")]),t._v(" "),n("th",[t._v("Paper / Source")]),t._v(" "),n("th",[t._v("Code")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("EditNTS (Dong et al., 2019)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("32.35")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1331",target:"_blank",rel:"noopener noreferrer"}},[t._v("EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/yuedongP/EditNTS",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("SeqLabel (Alva-Manchego et al., 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("30.50*")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/I17-1030",target:"_blank",rel:"noopener noreferrer"}},[t._v("Learning How to Simplify From Explicit Labeling of Complex-Simplified Text Pairs"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("Hybrid (Narayan and Gardent, 2014)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("53.94* (53.6)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("30.46*")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P/P14/P14-1041.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hybrid Simplification using Deep Semantics and Machine Translation"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/shashiongithub/Sentence-Simplification-ACL14",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("NSELSTM-B (Vu et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("53.42")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("17.47")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/N18-2013",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Memory-Augmented Neural Networks"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("PBMT-R (Wubben et al., 2012)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("46.31* (43.0)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("15.97*")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P12-1107",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification by Monolingual Machine Translation"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("RevILP (Woodsend and Lapata, 2011)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("42.0")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D11-1038",target:"_blank",rel:"noopener noreferrer"}},[t._v("Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("UNSUP (Narayan and Gardent, 2016)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("38.47")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/W16-6620",target:"_blank",rel:"noopener noreferrer"}},[t._v("Unsupervised Sentence Simplification Using Deep Semantics"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("TSM (Zhu et al., 2010)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("38.0")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/C10-1152",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Monolingual Tree-based Translation Model for Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("DRESS-LS (Zhang and Lapata, 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("36.32")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("27.24")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Deep Reinforcement Learning"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("DRESS (Zhang and Lapata, 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("34.53")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("27.48")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Deep Reinforcement Learning"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("NSELSTM-S (Vu et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("29.72")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("29.75")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/N18-2013",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Memory-Augmented Neural Networks"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("Pointer + Multi-task Entailment and Paraphrase Generation (Guo et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("27.23")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("29.58")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/C18-1039",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dynamic Multi-Level Multi-Task Learning for Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/HanGuo97/MultitaskSimplification",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])])])]),t._v(" "),n("h4",{attrs:{id:"coster-and-kauchack-2011"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#coster-and-kauchack-2011"}},[t._v("#")]),t._v(" Coster and Kauchack (2011)")]),t._v(" "),n("p",[n("a",{attrs:{href:"http://aclweb.org/anthology/P11-2117",target:"_blank",rel:"noopener noreferrer"}},[t._v("Coster and Kauchack (2011)"),n("OutboundLink")],1),t._v(" automatically aligned 137K sentence pairs from 10K Wikipedia articles, considering "),n("strong",[t._v("1-to-1 and 1-to-N alignments")]),t._v(", with "),n("strong",[t._v("one simplification reference per original sentence")]),t._v(". The corpus was split into 124K instances for training, 12K for development, and 1.3K for testing. The dataset is available "),n("a",{attrs:{href:"http://www.cs.pomona.edu/~dkauchak/simplification/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),n("OutboundLink")],1),t._v(". As before, models tested in this dataset are "),n("strong",[t._v("ranked by BLEU score")]),t._v(" and not SARI.")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("Model")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("BLEU")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("SARI")]),t._v(" "),n("th",[t._v("Paper / Source")]),t._v(" "),n("th",[t._v("Code")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("Moses-Del (Coster and Kauchak, 2011b)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("60.46")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/W11-1601",target:"_blank",rel:"noopener noreferrer"}},[t._v("Learning to Simplify Sentences Using Wikipedia"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("Moses (Coster and Kauchak, 2011a)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("59.87")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P11-2117",target:"_blank",rel:"noopener noreferrer"}},[t._v("Simple English Wikipedia: A New Text Simplification Task"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("SimpleTT (Feblowitz and Kauchak, 2013)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("56.4")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",[n("a",{attrs:{href:"aclweb.org/anthology/W13-2901"}},[t._v("Sentence Simplification as Tree Transduction")])]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("PBMT-R (Wubben et al., 2012)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("54.3*")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P12-1107",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification by Monolingual Machine Translation"),n("OutboundLink")],1)]),t._v(" "),n("td")])])]),t._v(" "),n("h4",{attrs:{id:"turk-corpus"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#turk-corpus"}},[t._v("#")]),t._v(" Turk Corpus")]),t._v(" "),n("p",[t._v("Together with defining SARI, "),n("a",{attrs:{href:"http://aclweb.org/anthology/Q16-1029",target:"_blank",rel:"noopener noreferrer"}},[t._v("Xu et al. (2016)"),n("OutboundLink")],1),t._v(" released a dataset properly collected to calculate this simplicity metric: "),n("strong",[t._v("1-to-1 alignments")]),t._v(" focused on paraphrasing transformations (extracted from PWKP), and "),n("strong",[t._v("multiple (8) simplification references per original sentence")]),t._v(" (collected through Amazon Mechanical Turk). The  "),n("a",{attrs:{href:"https://github.com/cocoxu/simplification/",target:"_blank",rel:"noopener noreferrer"}},[t._v("dataset"),n("OutboundLink")],1),t._v(" contains 2,350 sentences split into 2,000 instances for tuning and 350 for testing. For training, most models use "),n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[n("em",[t._v("WikiLarge")]),n("OutboundLink")],1),t._v(", which was compiled by "),n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zhang and Lapata (2017)"),n("OutboundLink")],1),t._v(" using alignments from other Wikipedia-based datasets ("),n("a",{attrs:{href:"http://aclweb.org/anthology/C10-1152",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zhu et al., 2010"),n("OutboundLink")],1),t._v("; "),n("a",{attrs:{href:"http://aclweb.org/anthology/D11-1038",target:"_blank",rel:"noopener noreferrer"}},[t._v("Woodsend and Lapata, 2011"),n("OutboundLink")],1),t._v("; "),n("a",{attrs:{href:"http://aclweb.org/anthology/P13-1151",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kauchak, 2013"),n("OutboundLink")],1),t._v("), and contains 296K instances of not only 1-to-1 alignments.")]),t._v(" "),n("p",[t._v("We present the models tested in this dataset "),n("strong",[t._v("ranked by SARI score")]),t._v(".")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("Model")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("BLEU")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("SARI")]),t._v(" "),n("th",[t._v("Paper / Source")]),t._v(" "),n("th",[t._v("Code")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("ACCESS (Martin et al., 2019)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("41.87")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://arxiv.org/abs/1910.02677",target:"_blank",rel:"noopener noreferrer"}},[t._v("Controllable Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/facebookresearch/access",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("DMASS + DCSS (Zhao et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("40.45")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D18-1355",target:"_blank",rel:"noopener noreferrer"}},[t._v("Integrating Transformer and Paraphrase Rules for Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/Sanqiang/text_simplification",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("SBSMT + PPDB + SARI (Xu et al, 2016)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("73.08* (72.36)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("39.96* (37.91)")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/Q16-1029",target:"_blank",rel:"noopener noreferrer"}},[t._v("Optimizing Statistical Machine Translation for Text Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/cocoxu/simplification/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("PBMT-R (Wubben et al., 2012)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("81.11*")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("38.56*")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P12-1107",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification by Monolingual Machine Translation"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("EditNTS (Dong et al., 2019)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("38.22")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1331",target:"_blank",rel:"noopener noreferrer"}},[t._v("EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/yuedongP/EditNTS",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("Pointer + Multi-task Entailment and Paraphrase Generation (Guo et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("81.49")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("37.45")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/C18-1039",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dynamic Multi-Level Multi-Task Learning for Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/HanGuo97/MultitaskSimplification",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("NTS + SARI (Nisioi et al., 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("80.69")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("37.25")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P17-2014",target:"_blank",rel:"noopener noreferrer"}},[t._v("Exploring Neural Text Simplification Models"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/senisioi/NeuralTextSimplification",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("DRESS-LS (Zhang and Lapata, 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("80.12")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("37.27")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Deep Reinforcement Learning"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("DRESS (Zhang and Lapata, 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("77.18")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("37.08")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Deep Reinforcement Learning"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("SeqLabel (Alva-Manchego et al., 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("37.08*")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/I17-1030",target:"_blank",rel:"noopener noreferrer"}},[t._v("Learning How to Simplify From Explicit Labeling of Complex-Simplified Text Pairs"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("NSELSTM-S (Vu et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("80.43")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("36.88")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/N18-2013",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Memory-Augmented Neural Networks"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("SEMoses (Sulem et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("74.49")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("36.70")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P18-1016",target:"_blank",rel:"noopener noreferrer"}},[t._v("Simple and Effective Text Simplification Using Semantic and Neural Methods"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/eliorsulem/simplification-acl2018",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("UnsupNTS (Surya et al., 2019)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("76.13")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("35.29")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1198",target:"_blank",rel:"noopener noreferrer"}},[t._v("Unsupervised Neural Text Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/subramanyamdvss/UnsupNTS",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("NSELSTM-B (Vu et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("92.02")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("33.43")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/N18-2013",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Memory-Augmented Neural Networks"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("Hybrid (Narayan and Gardent, 2014)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("48.97*")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("31.40*")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P/P14/P14-1041.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hybrid Simplification using Deep Semantics and Machine Translation"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/shashiongithub/Sentence-Simplification-ACL14",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])])])]),t._v(" "),n("h4",{attrs:{id:"other-datasets"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#other-datasets"}},[t._v("#")]),t._v(" Other Datasets")]),t._v(" "),n("p",[n("a",{attrs:{href:"http://aclweb.org/anthology/N15-1022",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hwang et al. (2015)"),n("OutboundLink")],1),t._v(" released a "),n("a",{attrs:{href:"http://ssli.ee.washington.edu/tial/projects/simplification/",target:"_blank",rel:"noopener noreferrer"}},[t._v("dataset"),n("OutboundLink")],1),t._v(" of 392K instances, while "),n("a",{attrs:{href:"http://aclweb.org/anthology/C16-1109",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kajiwara and Komachi (2016)"),n("OutboundLink")],1),t._v(" collected the "),n("a",{attrs:{href:"https://github.com/tmu-nlp/sscorpus",target:"_blank",rel:"noopener noreferrer"}},[t._v("sscorpus"),n("OutboundLink")],1),t._v(" of 493K instances, also from Main - Simple English Wikipedia article pairs. Both datasets contain only "),n("strong",[t._v("1-to-1 alignments")]),t._v(" with "),n("strong",[t._v("one simplification reference per original sentence")]),t._v(". Despite their bigger sizes and the more sophisticated sentence alignment algorithms used to collect them, these datasets are not commonly used in simplification research.")]),t._v(" "),n("h3",{attrs:{id:"newsela"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#newsela"}},[t._v("#")]),t._v(" Newsela")]),t._v(" "),n("p",[n("a",{attrs:{href:"http://aclweb.org/anthology/Q15-1021",target:"_blank",rel:"noopener noreferrer"}},[t._v("Xu et al. (2015)"),n("OutboundLink")],1),t._v(" introduced the Newsela corpus, which contains 1,130 news articles with four simplification versions each. The original article is considered version 0, and each simplification version goes from 1 to 4 (the highest being the simplest). These simplifications were produced manually by professional editors, considering children of different grade levels as target audience. Through manual evaluation on a subset of the data, "),n("a",{attrs:{href:"http://aclweb.org/anthology/Q15-1021",target:"_blank",rel:"noopener noreferrer"}},[t._v("Xu et al. (2015)"),n("OutboundLink")],1),t._v(" showed that there is a better presence and distribution of simplification transformations in Newsela than in PWKP.")]),t._v(" "),n("p",[t._v("The dataset can be requested "),n("a",{attrs:{href:"https://newsela.com/data/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),n("OutboundLink")],1),t._v(". However, researchers are not allowed to publicly shared splits of the data. This is not ideal for proper reproducibility and comparison among models.")]),t._v(" "),n("h4",{attrs:{id:"splits-by-zhang-and-lapata-2017"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#splits-by-zhang-and-lapata-2017"}},[t._v("#")]),t._v(" Splits by Zhang and Lapata (2017)")]),t._v(" "),n("p",[n("a",{attrs:{href:"http://aclweb.org/anthology/Q15-1021",target:"_blank",rel:"noopener noreferrer"}},[t._v("Xu et al. (2015)"),n("OutboundLink")],1),t._v(" generated sentence alignments between all versions of each article in the Newsela corpus. "),n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zhang and Lapata (2017)"),n("OutboundLink")],1),t._v(' imply that they used those alignments but removed some sentence pairs that are "too similar". In the end, they used a dataset composed of 94,208 instances for training, 1,129 instances for development, and 1,076 instances for testing. Their test set, in particular, contains only '),n("strong",[t._v("1-to-1 alignments")]),t._v(" with "),n("strong",[t._v("one simplification reference per original sentence")]),t._v(".")]),t._v(" "),n("p",[t._v("Using their splits, "),n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zhang and Lapata (2017)"),n("OutboundLink")],1),t._v(" trained and tested several models, which we include in our ranking. Other research that claims to have used the same dataset splits is also considered. Despite not being the ideal scenario, the models tested in this dataset are commonly "),n("strong",[t._v("ranked by SARI score")]),t._v(".")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("Model")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("BLEU")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("SARI")]),t._v(" "),n("th",[t._v("Paper / Source")]),t._v(" "),n("th",[t._v("Code")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("S2S-Cluster-FA (Kriz et al., 2019)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("37.22")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/N19-1317",target:"_blank",rel:"noopener noreferrer"}},[t._v("Complexity-Weighted Loss and Diverse Reranking for Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/rekriz11/sockeye-recipes",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("Pointer + Multi-task Entailment and Paraphrase Generation (Guo et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("11.14")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("33.22")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/C18-1039",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dynamic Multi-Level Multi-Task Learning for Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/HanGuo97/MultitaskSimplification",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("EditNTS (Dong et al., 2019)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("31.41")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1331",target:"_blank",rel:"noopener noreferrer"}},[t._v("EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/yuedongP/EditNTS",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("Hybrid (Narayan and Gardent, 2014)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("14.46*")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("30.00*")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P/P14/P14-1041.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hybrid Simplification using Deep Semantics and Machine Translation"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/shashiongithub/Sentence-Simplification-ACL14",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("NSELSTM-S (Vu et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("22.62")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("29.58")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/N18-2013",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Memory-Augmented Neural Networks"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("SeqLabel (Alva-Manchego et al., 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("29.53*")]),t._v(" "),n("td",[n("a",{attrs:{href:"https://www.aclweb.org/anthology/I17-1030",target:"_blank",rel:"noopener noreferrer"}},[t._v("Learning How to Simplify From Explicit Labeling of Complex-Simplified Text Pairs"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("NSELSTM-B (Vu et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("26.31")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("27.42")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/N18-2013",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Memory-Augmented Neural Networks"),n("OutboundLink")],1)]),t._v(" "),n("td")]),t._v(" "),n("tr",[n("td",[t._v("DRESS (Zhang and Lapata, 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("23.21")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("27.37")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Deep Reinforcement Learning"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("DMASS + DCSS (Zhao et al., 2018)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}}),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("27.28")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D18-1355",target:"_blank",rel:"noopener noreferrer"}},[t._v("Integrating Transformer and Paraphrase Rules for Sentence Simplification"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/Sanqiang/text_simplification",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("DRESS-LS (Zhang and Lapata, 2017)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("24.30")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("26.63")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification with Deep Reinforcement Learning"),n("OutboundLink")],1)]),t._v(" "),n("td",[n("a",{attrs:{href:"https://github.com/XingxingZhang/dress",target:"_blank",rel:"noopener noreferrer"}},[t._v("Official"),n("OutboundLink")],1)])]),t._v(" "),n("tr",[n("td",[t._v("PBMT-R (Wubben et al., 2012)")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("18.19*")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("15.77*")]),t._v(" "),n("td",[n("a",{attrs:{href:"http://aclweb.org/anthology/P12-1107",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sentence Simplification by Monolingual Machine Translation"),n("OutboundLink")],1)]),t._v(" "),n("td")])])]),t._v(" "),n("p",[t._v("As mentioned before, a big disadvantage of the Newsela corpus is that a unique train/dev/test split of the data is not (cannot be made?) publicly available. In addition, due to its characteristics, it is not clear what should be the best way to generate sentence alignments and split the data:")]),t._v(" "),n("ul",[n("li",[n("a",{attrs:{href:"http://aclweb.org/anthology/D17-1062",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zhang and Lapata (2017)"),n("OutboundLink")],1),t._v(' removed sentences from version pairs 0–1, 1–2, and 2–3 because they are "too similar to each other". This could prevent the model from learning when a sentence should not be simplified. In addition, their test set only considers 1-to-1 sentence alignments, even though it is possible to generate 1-to-N and N-to-1 sentence pairs as shown by other researchers ('),n("a",{attrs:{href:"http://aclweb.org/anthology/L18-1553",target:"_blank",rel:"noopener noreferrer"}},[t._v("Scarton et al., 2018"),n("OutboundLink")],1),t._v("; "),n("a",{attrs:{href:"http://aclweb.org/anthology/L18-1615",target:"_blank",rel:"noopener noreferrer"}},[t._v("Stajner et al., 2018"),n("OutboundLink")],1),t._v(").")]),t._v(" "),n("li",[n("a",{attrs:{href:"http://aclweb.org/anthology/I17-1030",target:"_blank",rel:"noopener noreferrer"}},[t._v("Alva-Manchego et al. (2017)"),n("OutboundLink")],1),t._v(", "),n("a",{attrs:{href:"http://aclweb.org/anthology/L18-1553",target:"_blank",rel:"noopener noreferrer"}},[t._v("Scarton et al. (2018)"),n("OutboundLink")],1),t._v(", and "),n("a",{attrs:{href:"http://www.aclweb.org/anthology/L18-1479",target:"_blank",rel:"noopener noreferrer"}},[t._v("Stajner and Nisioi (2018)"),n("OutboundLink")],1),t._v(" generate sentence alignments (using different algorithms) only between adjacent article versions (i.e. 0-1, 1-2, 2-3, and 3-4). Meanwhile, "),n("a",{attrs:{href:"http://aclweb.org/anthology/P18-2113",target:"_blank",rel:"noopener noreferrer"}},[t._v("Scarton and Specia (2018)"),n("OutboundLink")],1),t._v(" generate alignments between all versions (i.e., 0-{1,2,3,4}, 1-{2,3,4}, 2-{3,4}, and 3-4). The assumption behind using only adjacent versions is that, to write an article's simplification, an editor takes the immediately previous simplified version as basis (i.e. 0→1, 1→2, etc.). However, since the simplification manual followed by the Newsela editors is not public, it is not possible to corroborate that hypothesis.")])]),t._v(" "),n("p",[n("RouterLink",{attrs:{to:"/"}},[t._v("Go back to the README")])],1)])}),[],!1,null,null,null);e.default=r.exports}}]);
(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{242:function(t,e,r){"use strict";r.r(e);var a=r(1),n=Object(a.a)({},(function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("h1",{attrs:{id:"dialogue"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#dialogue"}},[t._v("#")]),t._v(" Dialogue")]),t._v(" "),r("p",[t._v("Dialogue is notoriously hard to evaluate. Past approaches have used human evaluation.")]),t._v(" "),r("h2",{attrs:{id:"dialogue-act-classification"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#dialogue-act-classification"}},[t._v("#")]),t._v(" Dialogue act classification")]),t._v(" "),r("p",[t._v("Dialogue act classification is the task of classifying an utterance with respect to the function it serves in a dialogue, i.e. the act the speaker is performing. Dialogue acts are a type of speech acts (for Speech Act Theory, see "),r("a",{attrs:{href:"http://www.hup.harvard.edu/catalog.php?isbn=9780674411524",target:"_blank",rel:"noopener noreferrer"}},[t._v("Austin (1975)"),r("OutboundLink")],1),t._v(" and "),r("a",{attrs:{href:"https://www.cambridge.org/core/books/speech-acts/D2D7B03E472C8A390ED60B86E08640E7",target:"_blank",rel:"noopener noreferrer"}},[t._v("Searle (1969)"),r("OutboundLink")],1),t._v(").")]),t._v(" "),r("h3",{attrs:{id:"switchboard-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#switchboard-corpus"}},[t._v("#")]),t._v(" Switchboard corpus")]),t._v(" "),r("p",[t._v("The "),r("a",{attrs:{href:"https://catalog.ldc.upenn.edu/ldc97s62",target:"_blank",rel:"noopener noreferrer"}},[t._v("Switchboard-1 corpus"),r("OutboundLink")],1),t._v(" is a telephone speech corpus, consisting of about 2,400 two-sided telephone conversation among 543 speakers with about 70 provided conversation topics. The dataset includes the audio files and the transcription files, as well as information about the speakers and the calls.")]),t._v(" "),r("p",[t._v("The Switchboard Dialogue Act Corpus (SwDA) ["),r("a",{attrs:{href:"https://web.stanford.edu/~jurafsky/swb1_dialogact_annot.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[t._v("download"),r("OutboundLink")],1),t._v("] extends the Switchboard-1 corpus with tags from the "),r("a",{attrs:{href:"https://web.stanford.edu/~jurafsky/ws97/manual.august1.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("SWBD-DAMSL tagset"),r("OutboundLink")],1),t._v(", which is an augmentation to the Discourse Annotation and Markup System of Labeling (DAMSL) tagset. The 220 tags were reduced to 42 tags by clustering in order to improve the language model on the Switchboard corpus. A subset of the Switchboard-1 corpus consisting of 1155 conversations was used. The resulting tags include dialogue acts like statement-non-opinion, acknowledge, statement-opinion, agree/accept, etc."),r("br"),t._v("\nAnnotated example:"),r("br"),t._v(" "),r("em",[t._v("Speaker:")]),t._v(" A, "),r("em",[t._v("Dialogue Act:")]),t._v(" Yes-No-Question, "),r("em",[t._v("Utterance:")]),t._v(" So do you go to college right now?")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Accuracy")]),t._v(" "),r("th",[t._v("Paper / Source")]),t._v(" "),r("th",[t._v("Code")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("CRF-ASN (Chen et al., 2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("81.3")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1711.05568",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dialogue Act Recognition via CRF-Attentive Structured Network"),r("OutboundLink")],1)]),t._v(" "),r("td")]),t._v(" "),r("tr",[r("td",[t._v("Bi-LSTM-CRF (Kumar et al., 2017)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("79.2")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1709.04250",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dialogue Act Sequence Labeling using Hierarchical encoder with CRF"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/YanWenqiang/HBLSTM-CRF",target:"_blank",rel:"noopener noreferrer"}},[t._v("Link"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("RNN with 3 utterances in context (Bothe et al., 2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("77.34")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1805.06280",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Context-based Approach for Dialogue Act Recognition using Simple Recurrent Neural Networks"),r("OutboundLink")],1)]),t._v(" "),r("td")])])]),t._v(" "),r("h3",{attrs:{id:"icsi-meeting-recorder-dialog-act-mrda-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#icsi-meeting-recorder-dialog-act-mrda-corpus"}},[t._v("#")]),t._v(" ICSI Meeting Recorder Dialog Act (MRDA) corpus")]),t._v(" "),r("p",[t._v("The "),r("a",{attrs:{href:"http://www1.icsi.berkeley.edu/Speech/mr/",target:"_blank",rel:"noopener noreferrer"}},[t._v("MRDA corpus"),r("OutboundLink")],1),t._v(" ["),r("a",{attrs:{href:"http://www.icsi.berkeley.edu/~ees/dadb/icsi_mrda+hs_corpus_050512.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[t._v("download"),r("OutboundLink")],1),t._v("] consists of about 75 hours of speech from 75 naturally-occurring meetings among 53 speakers. The tagset used for labeling is a modified version of the SWBD-DAMSL tagset. It is annotated with three types of information: marking of the dialogue act segment boundaries, marking of the dialogue acts and marking of correspondences between dialogue acts."),r("br"),t._v("\nAnnotated example:"),r("br"),t._v(" "),r("em",[t._v("Time:")]),t._v(" 2804-2810, "),r("em",[t._v("Speaker:")]),t._v(" c6, "),r("em",[t._v("Dialogue Act:")]),t._v(" s^bd, "),r("em",[t._v("Transcript:")]),t._v(" i mean these are just discriminative."),r("br"),t._v('\nMultiple dialogue acts are separated by "^".')]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Accuracy")]),t._v(" "),r("th",[t._v("Paper / Source")]),t._v(" "),r("th",[t._v("Code")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("CRF-ASN (Chen et al., 2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("91.7")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1711.05568",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dialogue Act Recognition via CRF-Attentive Structured Network"),r("OutboundLink")],1)]),t._v(" "),r("td")]),t._v(" "),r("tr",[r("td",[t._v("Bi-LSTM-CRF (Kumar et al., 2017)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("90.9")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1709.04250",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dialogue Act Sequence Labeling using Hierarchical encoder with CRF"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/YanWenqiang/HBLSTM-CRF",target:"_blank",rel:"noopener noreferrer"}},[t._v("Link"),r("OutboundLink")],1)])])])]),t._v(" "),r("h2",{attrs:{id:"dialogue-state-tracking"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#dialogue-state-tracking"}},[t._v("#")]),t._v(" Dialogue state tracking")]),t._v(" "),r("p",[t._v("Dialogue state tacking consists of determining at each turn of a dialogue the\nfull representation of what the user wants at that point in the dialogue,\nwhich contains a goal constraint, a set of requested slots, and the user's dialogue act.")]),t._v(" "),r("h3",{attrs:{id:"second-dialogue-state-tracking-challenge"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#second-dialogue-state-tracking-challenge"}},[t._v("#")]),t._v(" Second dialogue state tracking challenge")]),t._v(" "),r("p",[t._v("For goal-oriented dialogue, the dataset of the "),r("a",{attrs:{href:"http://www.aclweb.org/anthology/W14-4337",target:"_blank",rel:"noopener noreferrer"}},[t._v("second Dialogue Systems Technology Challenges"),r("OutboundLink")],1),t._v("\n(DSTC2) is a common evaluation dataset. The DSTC2 focuses on the restaurant search domain. Models are\nevaluated based on accuracy on both individual and joint slot tracking.")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Request")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Area")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Food")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Price")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Joint")]),t._v(" "),r("th",[t._v("Paper / Source")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("Zhong et al. (2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("97.5")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("74.5")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1805.09655",target:"_blank",rel:"noopener noreferrer"}},[t._v("Global-locally Self-attentive Dialogue State Tracker"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Liu et al. (2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("90")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("84")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("92")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("72")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1804.06512",target:"_blank",rel:"noopener noreferrer"}},[t._v("Dialogue Learning with Human Teaching and Feedback in End-to-End Trainable Task-Oriented Dialogue Systems"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Neural belief tracker (Mrkšić et al., 2017)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("96.5")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("90")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("84")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("94")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("73.4")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1606.03777",target:"_blank",rel:"noopener noreferrer"}},[t._v("Neural Belief Tracker: Data-Driven Dialogue State Tracking"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("RNN (Henderson et al., 2014)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("95.7")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("92")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("86")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("86")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("69")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://svr-ftp.eng.cam.ac.uk/~sjy/papers/htyo14.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised gate"),r("OutboundLink")],1)])])])]),t._v(" "),r("h3",{attrs:{id:"wizard-of-oz"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wizard-of-oz"}},[t._v("#")]),t._v(" Wizard-of-Oz")]),t._v(" "),r("p",[t._v("The "),r("a",{attrs:{href:"https://arxiv.org/pdf/1606.03777.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("WoZ 2.0 dataset"),r("OutboundLink")],1),t._v(" is a newer dialogue state tracking dataset whose evaluation is detached from the noisy output of speech recognition systems. Similar to DSTC2, it covers the restaurant search domain and has identical evaluation.")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Request")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Joint")]),t._v(" "),r("th",[t._v("Paper / Source")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("Zhong et al. (2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("97.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("88.1")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1805.09655",target:"_blank",rel:"noopener noreferrer"}},[t._v("Global-locally Self-attentive Dialogue State Tracker"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Neural belief tracker (Mrkšić et al., 2017)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("96.5")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("84.4")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1606.03777",target:"_blank",rel:"noopener noreferrer"}},[t._v("Neural Belief Tracker: Data-Driven Dialogue State Tracking"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("RNN (Henderson et al., 2014)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("87.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("70.8")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://svr-ftp.eng.cam.ac.uk/~sjy/papers/htyo14.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised gate"),r("OutboundLink")],1)])])])]),t._v(" "),r("h3",{attrs:{id:"multiwoz"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#multiwoz"}},[t._v("#")]),t._v(" MultiWOZ")]),t._v(" "),r("p",[t._v("The "),r("a",{attrs:{href:"https://arxiv.org/abs/1810.00278",target:"_blank",rel:"noopener noreferrer"}},[t._v("MultiWOZ dataset"),r("OutboundLink")],1),t._v(" is a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora. The dialogue are set between a tourist and a clerk in the information. It spans over 7 domains.")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Joint")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Slot")]),t._v(" "),r("th",[t._v("Paper / Source")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("Ramadan et al. (2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("15.57")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("89.53")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P18-2069",target:"_blank",rel:"noopener noreferrer"}},[t._v("Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Zhong et al. (2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("35.57")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("95.44")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1805.09655",target:"_blank",rel:"noopener noreferrer"}},[t._v("Global-locally Self-attentive Dialogue State Tracker"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Nouri and Hosseini-Asl (2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("36.27")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("98.42")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1812.00899.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Toward Scalable Neural Dialogue State Tracking Model"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Wu et al. (2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("48.62")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("96.92")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1905.08743.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Transferable Multi-Domain State Generator for Task-OrientedDialogue System"),r("OutboundLink")],1)])])])]),t._v(" "),r("h2",{attrs:{id:"retrieval-based-chatbots"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#retrieval-based-chatbots"}},[t._v("#")]),t._v(" Retrieval-based Chatbots")]),t._v(" "),r("p",[t._v("These systems take as input a context and a list of possible responses and rank the responses, returning the highest ranking one.")]),t._v(" "),r("h3",{attrs:{id:"ubuntu-irc-data"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#ubuntu-irc-data"}},[t._v("#")]),t._v(" Ubuntu IRC Data")]),t._v(" "),r("p",[t._v("There are several corpra based on the "),r("a",{attrs:{href:"https://irclogs.ubuntu.com",target:"_blank",rel:"noopener noreferrer"}},[t._v("Ubuntu IRC Channel Logs"),r("OutboundLink")],1),t._v(":")]),t._v(" "),r("ul",[r("li",[r("a",{attrs:{href:""}},[t._v("Uthus and Aha (2013)")]),t._v(", available "),r("a",{attrs:{href:"https://daviduthus.org/UCC/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(", the first dataset to use the resource, but not for retrieval-based chatbot research.")]),t._v(" "),r("li",[t._v("UDC v1, "),r("a",{attrs:{href:"https://arxiv.org/abs/1506.08909",target:"_blank",rel:"noopener noreferrer"}},[t._v("Lowe et al. (2015)"),r("OutboundLink")],1),t._v(", available "),r("a",{attrs:{href:"http://dataset.cs.mcgill.ca/ubuntu-corpus-1.0/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(", the first version of the Ubuntu Dialogue Corpus.")]),t._v(" "),r("li",[t._v("UDC v2, "),r("a",{attrs:{href:"http://dad.uni-bielefeld.de/index.php/dad/article/view/3698",target:"_blank",rel:"noopener noreferrer"}},[t._v("Lowe et al. (2017)"),r("OutboundLink")],1),t._v(", available "),r("a",{attrs:{href:"https://arxiv.org/abs/1506.08909",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(", the second version of the Ubuntu Dialogue Corpus.")]),t._v(" "),r("li",[t._v("DSTC 7, "),r("a",{attrs:{href:"http://workshop.colips.org/dstc7/papers/dstc7_task1_final_report.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Gunasekara et al. (2019)"),r("OutboundLink")],1),t._v(", available "),r("a",{attrs:{href:"https://ibm.github.io/dstc-noesis/public/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(", the data from DSTC 7 track 1.")]),t._v(" "),r("li",[t._v("DSTC 8, "),r("a",{attrs:{href:""}},[t._v("Gunasekara et al. (2020)")]),t._v(", available "),r("a",{attrs:{href:"https://github.com/dstc8-track2/NOESIS-II/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(", the data from DSTC 8 track 2.")])]),t._v(" "),r("p",[t._v("Each version of the dataset contains a set of dialogues from the IRC channel, extracted by automatically disentangling conversations occurring simultaneously. See below for results on the disentanglement process.")]),t._v(" "),r("p",[t._v("The exact tasks used vary slightly, but all consider variations of Recall_N@K, which means how often the true answer is in the top K options when there are N total candidates.")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Data")]),t._v(" "),r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_2@1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_10@1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_100@1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_100@10")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_100@50")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("MRR")]),t._v(" "),r("th",[t._v("Paper / Source")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("DSTC 8")]),t._v(" "),r("td"),t._v(" "),r("td",{staticStyle:{"text-align":"center"}}),t._v(" "),r("td",{staticStyle:{"text-align":"center"}}),t._v(" "),r("td",{staticStyle:{"text-align":"center"}}),t._v(" "),r("td",{staticStyle:{"text-align":"center"}}),t._v(" "),r("td",{staticStyle:{"text-align":"center"}}),t._v(" "),r("td",{staticStyle:{"text-align":"center"}}),t._v(" "),r("td")]),t._v(" "),r("tr",[r("td",[t._v("DSTC 7")]),t._v(" "),r("td",[t._v("Seq-Att-Network (Chen and Wang, 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("64.5")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("90.2")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("99.4")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("73.5")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://workshop.colips.org/dstc7/papers/07.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sequential Attention-based Network for Noetic End-to-End Response Selection"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("UDC v2")]),t._v(" "),r("td",[t._v("DAM (Zhou et al. 2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("93.8")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("76.7")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://www.aclweb.org/anthology/P18-1103",target:"_blank",rel:"noopener noreferrer"}},[t._v("Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("UDC v2")]),t._v(" "),r("td",[t._v("SMN (Wu et al. 2017)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("92.3")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("72.3")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1612.01627.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("UDC v2")]),t._v(" "),r("td",[t._v("Multi-View (Zhou et al. 2017)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("90.8")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("66.2")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://aclweb.org/anthology/D16-1036",target:"_blank",rel:"noopener noreferrer"}},[t._v("Multi-view Response Selection for Human-Computer Conversation"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("UDC v2")]),t._v(" "),r("td",[t._v("Bi-LSTM (Kadlec et al. 2015)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("89.5")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("63.0")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1510.03753.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Improved Deep Learning Baselines for Ubuntu Corpus Dialogs"),r("OutboundLink")],1)])])])]),t._v(" "),r("p",[t._v("Additional results can be found in the DSTC task reports linked above.")]),t._v(" "),r("h3",{attrs:{id:"reddit-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#reddit-corpus"}},[t._v("#")]),t._v(" Reddit Corpus")]),t._v(" "),r("p",[t._v("The "),r("a",{attrs:{href:"https://arxiv.org/abs/1904.06472",target:"_blank",rel:"noopener noreferrer"}},[t._v("Reddit Corpus"),r("OutboundLink")],1),t._v(" contains 726 million multi-turn dialogues from the Reddit board. Reddit  is an American social news aggregation website, where users can post links, and take partin discussions on these post. The task of Reddit Corpus is to select the correct response from 100 candidates (others are negatively sampled) by considering previous conversation history.  Models are evaluated with the Recall 1 at 100 metric (the 1-of-100 ranking accuracy). You can find more details at "),r("a",{attrs:{href:"https://github.com/PolyAI-LDN/conversational-datasets",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(".")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_1@100")]),t._v(" "),r("th",[t._v("Paper / Source")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("PolyAI Encoder (Henderson et al. 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("61.3")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1904.06472.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Repository of Conversational Dataset"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("USE (Cer et al. 2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("47.7")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1803.11175",target:"_blank",rel:"noopener noreferrer"}},[t._v("Universal Sentence Encoder"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("BERT (Devlin et al. 2017)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("24.0")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1810.04805",target:"_blank",rel:"noopener noreferrer"}},[t._v("BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("ELMO (Peters et al. 2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("19.3")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/abs/1802.05365",target:"_blank",rel:"noopener noreferrer"}},[t._v("Deep contextualized word representations"),r("OutboundLink")],1)])])])]),t._v(" "),r("h3",{attrs:{id:"advising-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#advising-corpus"}},[t._v("#")]),t._v(" Advising Corpus")]),t._v(" "),r("p",[t._v("The "),r("a",{attrs:{href:"http://workshop.colips.org/dstc7/papers/dstc7_task1_final_report.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Advising Corpus"),r("OutboundLink")],1),t._v(", available "),r("a",{attrs:{href:"https://ibm.github.io/dstc-noesis/public/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(", contains a collection of conversations between a student and an advisor at the University of Michigan. They were released as part of DSTC 7 track 1 and used again in DSTC 8 track 2.")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Data")]),t._v(" "),r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_100@1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_100@10")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("R_100@50")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("MRR")]),t._v(" "),r("th",[t._v("Paper / Source")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("DSTC 7")]),t._v(" "),r("td",[t._v("Seq-Att-Network (Chen and Wang, 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("21.4")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("63.0")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("94.8")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("33.9")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://workshop.colips.org/dstc7/papers/07.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Sequential Attention-based Network for Noetic End-to-End Response Selection"),r("OutboundLink")],1)])])])]),t._v(" "),r("h2",{attrs:{id:"generative-based-chatbots"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#generative-based-chatbots"}},[t._v("#")]),t._v(" Generative-based Chatbots")]),t._v(" "),r("p",[t._v("The main task of generative-based chatbot is to generate consistent and engaging response given the context.")]),t._v(" "),r("h3",{attrs:{id:"personalized-chit-chat"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#personalized-chit-chat"}},[t._v("#")]),t._v(" Personalized Chit-chat")]),t._v(" "),r("p",[t._v("The task of persinalized chit-chat dialogue generation is first proposed by "),r("a",{attrs:{href:"https://arxiv.org/pdf/1801.07243.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("PersonaChat"),r("OutboundLink")],1),t._v(". The motivation is to enhance the engagingness and consistency of chit-chat bots via endowing explicit personas to agents. Here the "),r("code",[t._v("persona")]),t._v(' is defined as several profile natural language sentences like "I weight 300 pounds.". NIPS 2018 has hold a competition '),r("a",{attrs:{href:"http://convai.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("The Conversational Intelligence Challenge 2 (ConvAI2)"),r("OutboundLink")],1),t._v(" based on the dataset. The Evaluation metric is F1, Hits@1 and ppl. F1 evaluates on the word-level, and Hits@1 represents the probability of the real next utterance ranking the highest according to the model, while ppl is perplexity for language modeling. The following results are reported on dev set (test set is still hidden), almost of them are borrowed from "),r("a",{attrs:{href:"https://github.com/DeepPavlov/convai/blob/master/leaderboards.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("ConvAI2 Leaderboard"),r("OutboundLink")],1),t._v(".")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("F1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Hits@1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("ppl")]),t._v(" "),r("th",[t._v("Paper / Source")]),t._v(" "),r("th",[t._v("Code")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("TransferTransfo (Thomas et al. 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("19.09")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("82.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("17.51")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1901.08149.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/huggingface/transfer-learning-conv-ai",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Lost In Conversation")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("17.79")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("17.3")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://convai.io/NeurIPSParticipantSlides.pptx",target:"_blank",rel:"noopener noreferrer"}},[t._v("NIPS 2018 Workshop Presentation"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/atselousov/transformer_chatbot",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Seq2Seq + Attention (Dzmitry et al. 2014)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("16.18")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("12.6")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("29.8")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1409.0473.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Neural Machine Translation by Jointly Learning to Align and Translate"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/facebookresearch/ParlAI/tree/master/projects/convai2/baselines/seq2seq",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("KV Profile Memory (Zhang et al. 2018)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("11.9")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("55.2")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("-")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://arxiv.org/pdf/1801.07243.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Personalizing Dialogue Agents: I have a dog, do you have pets too?"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/facebookresearch/ParlAI/tree/master/projects/convai2/baselines/kvmemnn",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])])])]),t._v(" "),r("h2",{attrs:{id:"disentanglement"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#disentanglement"}},[t._v("#")]),t._v(" Disentanglement")]),t._v(" "),r("p",[t._v("As noted for the Ubuntu data above, sometimes multiple conversations are mixed together in a single channel. Work on conversation disentanglement aims to separate out conversations. There are two main resources for the task.")]),t._v(" "),r("p",[t._v("This can be formultated as a clustering problem, with no clear best metric. Several metrics are considered:")]),t._v(" "),r("ul",[r("li",[t._v("Variation of Information")]),t._v(" "),r("li",[t._v("F-1 over 1-1 matched clusters using max-flow")]),t._v(" "),r("li",[t._v("Precision, Recall, and F-score on exact match for clusters")]),t._v(" "),r("li",[t._v("Local overlap")]),t._v(" "),r("li",[t._v("Another form of F-1 defined by "),r("a",{attrs:{href:"https://dl.acm.org/citation.cfm?doid=1148170.1148180",target:"_blank",rel:"noopener noreferrer"}},[t._v("Shen et al. (2006)"),r("OutboundLink")],1)])]),t._v(" "),r("h3",{attrs:{id:"ubuntu-irc"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#ubuntu-irc"}},[t._v("#")]),t._v(" Ubuntu IRC")]),t._v(" "),r("p",[t._v("Manually labeled by "),r("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1374",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kummerfeld et al. (2019)"),r("OutboundLink")],1),t._v(", this data is available "),r("a",{attrs:{href:"https://jkk.name/irc-disentanglement/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(".")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("VI")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("1-1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Precision")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Recall")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("F-Score")]),t._v(" "),r("th",[t._v("Paper / Source")]),t._v(" "),r("th",[t._v("Code")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("FF ensemble: Vote      (Kummerfeld et al., 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("91.5")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("76.0")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("36.3")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("39.7")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("38.0")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1374/",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Large-Scale Corpus for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://jkk.name/irc-disentanglement",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Feedforward            (Kummerfeld et al., 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("91.3")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("75.6")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("34.6")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("38.0")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("36.2")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1374/",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Large-Scale Corpus for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://jkk.name/irc-disentanglement",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("FF ensemble: Intersect (Kummerfeld et al., 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("69.3")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("26.6")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("67.0")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("21.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("32.1")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1374/",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Large-Scale Corpus for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://jkk.name/irc-disentanglement",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Linear                 (Elsner and Charniak, 2008)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("82.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("51.4")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("12.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("21.5")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("15.5")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P08-1095/",target:"_blank",rel:"noopener noreferrer"}},[t._v("You Talking to Me? A Corpus and Algorithm for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.asc.ohio-state.edu/elsner.14/resources/chat-distr.tgz",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Heuristic              (Lowe et al., 2015)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("80.6")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("53.7")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("10.8")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("7.6")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("8.9")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://dad.uni-bielefeld.de/index.php/dad/article/view/3698",target:"_blank",rel:"noopener noreferrer"}},[t._v("Training End-to-End Dialogue Systems with the Ubuntu Dialogue Corpus"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/npow/ubuntu-corpus",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])])])]),t._v(" "),r("h3",{attrs:{id:"linux-irc"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#linux-irc"}},[t._v("#")]),t._v(" Linux IRC")]),t._v(" "),r("p",[t._v("This data has been manually annotated three times:")]),t._v(" "),r("ul",[r("li",[t._v("By "),r("a",{attrs:{href:"https://www.aclweb.org/anthology/P08-1095",target:"_blank",rel:"noopener noreferrer"}},[t._v("Elsner and Charniak (2008)"),r("OutboundLink")],1),t._v(", available "),r("a",{attrs:{href:"https://www.asc.ohio-state.edu/elsner.14/resources/chat-distr.tgz",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(".")]),t._v(" "),r("li",[t._v("A portion by "),r("a",{attrs:{href:"https://aclweb.org/anthology/I17-1062/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Mehri and Carenini (2017)"),r("OutboundLink")],1),t._v(", available "),r("a",{attrs:{href:"http://shikib.com/td_annotations",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(".")]),t._v(" "),r("li",[t._v("By "),r("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1374",target:"_blank",rel:"noopener noreferrer"}},[t._v("Kummerfeld et al. (2019)"),r("OutboundLink")],1),t._v(", available "),r("a",{attrs:{href:"https://jkk.name/irc-disentanglement/",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),r("OutboundLink")],1),t._v(".")])]),t._v(" "),r("table",[r("thead",[r("tr",[r("th",[t._v("Data")]),t._v(" "),r("th",[t._v("Model")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("1-1")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Local")]),t._v(" "),r("th",{staticStyle:{"text-align":"center"}},[t._v("Shen F-1")]),t._v(" "),r("th",[t._v("Paper / Source")]),t._v(" "),r("th",[t._v("Code")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("Kummerfeld")]),t._v(" "),r("td",[t._v("Linear     (Elsner and Charniak, 2008)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("59.7")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("80.8")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("63.0")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P08-1095/",target:"_blank",rel:"noopener noreferrer"}},[t._v("You Talking to Me? A Corpus and Algorithm for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.asc.ohio-state.edu/elsner.14/resources/chat-distr.tgz",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Kummerfeld")]),t._v(" "),r("td",[t._v("Feedforward (Kummerfeld et al., 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("57.7")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("80.3")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("59.8")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1374/",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Large-Scale Corpus for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://jkk.name/irc-disentanglement",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Kummerfeld")]),t._v(" "),r("td",[t._v("Heuristic   (Lowe et al., 2015)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("43.4")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("67.9")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("50.7")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://dad.uni-bielefeld.de/index.php/dad/article/view/3698",target:"_blank",rel:"noopener noreferrer"}},[t._v("Training End-to-End Dialogue Systems with the Ubuntu Dialogue Corpus"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/npow/ubuntu-corpus",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Elsner")]),t._v(" "),r("td",[t._v("Linear     (Elsner and Charniak, 2008)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("53.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("81.9")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("55.1")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P08-1095/",target:"_blank",rel:"noopener noreferrer"}},[t._v("You Talking to Me? A Corpus and Algorithm for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.asc.ohio-state.edu/elsner.14/resources/chat-distr.tgz",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Elsner")]),t._v(" "),r("td",[t._v("Feedforward (Kummerfeld et al., 2019)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("52.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("77.8")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("53.8")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/P19-1374/",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Large-Scale Corpus for Conversation Disentanglement"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://jkk.name/irc-disentanglement",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])]),t._v(" "),r("tr",[r("td",[t._v("Elsner")]),t._v(" "),r("td",[t._v("Wang and Oard (2009)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("47.0")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("75.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("52.8")]),t._v(" "),r("td",[r("a",{attrs:{href:"https://www.aclweb.org/anthology/N09-1023/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Context-based Message Expansion for Disentanglement of Interleaved Text Conversations"),r("OutboundLink")],1)]),t._v(" "),r("td",[t._v("-")])]),t._v(" "),r("tr",[r("td",[t._v("Elsner")]),t._v(" "),r("td",[t._v("Heuristic   (Lowe et al., 2015)")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("45.1")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("73.8")]),t._v(" "),r("td",{staticStyle:{"text-align":"center"}},[t._v("51.8")]),t._v(" "),r("td",[r("a",{attrs:{href:"http://dad.uni-bielefeld.de/index.php/dad/article/view/3698",target:"_blank",rel:"noopener noreferrer"}},[t._v("Training End-to-End Dialogue Systems with the Ubuntu Dialogue Corpus"),r("OutboundLink")],1)]),t._v(" "),r("td",[r("a",{attrs:{href:"https://github.com/npow/ubuntu-corpus",target:"_blank",rel:"noopener noreferrer"}},[t._v("Code"),r("OutboundLink")],1)])])])])])}),[],!1,null,null,null);e.default=n.exports}}]);